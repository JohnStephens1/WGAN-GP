{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d8f80-c4fa-4fa0-b68d-c4f03127c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306aad3-e460-4e03-b026-407c784b22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['TENSORBOARD_BINARY'] = r'C:\\Users\\johna\\Documents\\A_Documents\\Programming\\Python\\.my_envs\\datascience\\Scripts\\tensorboard.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f45f55-194f-4bd9-b7ee-003cb92c5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23baa659-1271-42bf-9c7f-eaefbbfc9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paths:\n",
    "\tCURRENT_MODEL = 'v8'\n",
    "\tCWD = Path.cwd()\n",
    "\t\n",
    "\tHISTORY_DIR = CWD/'history'\n",
    "\tMODEL_DIR = HISTORY_DIR/CURRENT_MODEL\n",
    "\t\n",
    "\tLOG_DIR = MODEL_DIR/'logs'\n",
    "\tSAVED_MODELS_DIR = MODEL_DIR/'saved_models'\n",
    "\tGENERATED_IMAGES_DIR = MODEL_DIR/'generated_images'\n",
    "\t\n",
    "\tCHECKPOINT_DIR = SAVED_MODELS_DIR/'checkpoints'\n",
    "\tSINGLE_IMAGE_DIR = GENERATED_IMAGES_DIR/'single'\n",
    "\tCOLLECTION_DIR = GENERATED_IMAGES_DIR/'collection'\n",
    "\t\n",
    "\tDS_PATH = Path(r'E:\\datasets\\cat-faces')\n",
    "\t# DS_PATH = Path(r'E:\\datasets\\monet-paintings\\monet_jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a9cb8-4240-4f20-9aeb-e17b154ecddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERS_TO_SETUP = [\n",
    "\tPaths.HISTORY_DIR,\n",
    "\tPaths.MODEL_DIR,\n",
    "\t\n",
    "\tPaths.SAVED_MODELS_DIR,\n",
    "\tPaths.GENERATED_IMAGES_DIR,\n",
    "\t\n",
    "\tPaths.CHECKPOINT_DIR,\n",
    "\tPaths.SINGLE_IMAGE_DIR,\n",
    "\tPaths.COLLECTION_DIR\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcfcaf-bccb-4f7c-8541-bbc69fc1bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5c2fe-e8a9-49d1-a2b7-d6422efff619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "\tpath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b6562-7120-42e1-b78d-904388c7c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_folders(paths: list):\n",
    "\tfor path in paths:\n",
    "\t\tmkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7b36b-5f8a-47a9-a6f8-8cc56c08a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "\tplt.imshow(image.astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20098b5-fb04-495b-96f9-852f6675338b",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43d92c-e382-4145-9794-e94fae731301",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (64, 64, 3)\n",
    "BATCHSIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe17b39-2f88-4746-b07b-e94ad599a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "\treturn (images-127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8731882-831b-453b-aa1d-e7519e07af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_images(images):\n",
    "\treturn np.array((images*127.5+127.5), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e463293-f0b9-403b-8893-f69efbf1fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, new_size=IMAGE_SHAPE[:-1], interpolation=cv2.INTER_AREA):\n",
    "\treturn np.array([cv2.resize(image, new_size, interpolation=interpolation) for image in images], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b32ab-6920-4887-84c1-33ea5ad88dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images():\n",
    "\timages = np.array([plt.imread(image) for image in (Paths.DS_PATH).glob('*')], dtype='float32')\n",
    "\t# resized_images = resize_images(images)\n",
    "\t# assert resized_images.shape[1:] == IMAGE_SHAPE, f'input images have the wrong dimensions! {resized_images.shape}'\n",
    "\t# normalized_images = normalize_images(resized_images)\n",
    "\tassert images.shape[1:] == IMAGE_SHAPE, f'images have the wrong shape! {images.shape}'\n",
    "\tnormalized_images = normalize_images(images)\n",
    "\treturn normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaac5cd-5c4b-4352-8cb4-476e0f3c0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = prepare_images()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(images.shape[0]).batch(BATCHSIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ed8b7-7ecc-47d6-8a0d-cdbbb9110791",
   "metadata": {},
   "source": [
    "### model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0a429-af20-490d-b6a5-c5ab2ad02533",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_STEP = 1000*len(images)\n",
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c7e5b-3200-4fe8-ae38-6efe94b62da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_images(generator, latent_dim=LATENT_DIM, training=False):\n",
    "\tnoise = tf.random.normal((12, latent_dim))\n",
    "\t\n",
    "\tgenerated_images = generator(noise, training=training)\n",
    "\tgenerated_images = denormalize_images(generated_images)\n",
    "\n",
    "\tdisplay.clear_output(True)\n",
    "\n",
    "\tf, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\tfor i, ax in enumerate(axs.flatten()):\n",
    "\t\tax.imshow(generated_images[i])\n",
    "\t\tax.axis('off')\n",
    "\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55318909-2cbd-4c22-9261-6b962e12f98c",
   "metadata": {},
   "source": [
    "#### blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7385ec-bdeb-4320-997e-fede2f77f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e38824-ff40-41c3-bd31-ba1202793044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(x, n_filters, kernel_size=(3, 3), strides=(2, 2), padding='same'):\n",
    "\tx = layers.Conv2D(n_filters, kernel_size, strides, padding)(x)\n",
    "\tx = layers.LeakyReLU(0.2)(x)\n",
    "\tx = layers.Dropout(0.3)(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7394e97-b60b-462b-93a6-887d17234602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_conv_block(x, n_filters, kernel_size=(3, 3), strides=(2, 2), padding='same'):\n",
    "\tx = layers.Conv2D(n_filters, kernel_size, strides, padding)(x)\n",
    "\tx = layers.LeakyReLU(0.2)(x)\n",
    "\tx = layers.LayerNormalization()(x)\n",
    "\tx = layers.Dropout(0.3)(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab51c21-dc37-40a2-824e-2ec8a51d2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposed_conv_block(x, n_filters, kernel_size=(3, 3), strides=(2, 2), padding=('same')):\n",
    "\tx = layers.Conv2DTranspose(n_filters, kernel_size, strides, padding, use_bias=False)(x)\n",
    "\tx = layers.LeakyReLU(0.2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84505ed8-03a6-49d1-9369-678f89d14df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_conv_block(x, n_filters, kernel_size=(3, 3), strides=(1, 1), padding='same'):\n",
    "\tx = layers.UpSampling2D()(x)\n",
    "\tx = layers.Conv2D(n_filters, kernel_size, strides, padding)\n",
    "\tx = layers.LeakyReLU(0.2)(x)\n",
    "\tx = layers.LayerNormalization()(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff225d-efc4-46bf-aec3-6af89c9c7461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upsampling_transposed_conv_block(x, n_filters, kernel_size=(3, 3), strides=(1, 1), padding='same'):\n",
    "\tx = layers.UpSampling2D()(x)\n",
    "\tx = layers.Conv2DTranspose(n_filters, kernel_size, strides, padding)(x)\n",
    "\tx = layers.LeakyReLU(0.2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081f449-2b36-4def-a0d7-889d426cf1f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ff16b-463a-4d49-aedc-96a61c382a29",
   "metadata": {},
   "source": [
    "##### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69921561-54b4-43ff-ae4f-b0d21250a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_model(input_size, optimizer, loss_function):\n",
    "\tinitial_dimensions = (8, 8)\n",
    "\tinputs = layers.Input(input_size)\n",
    "\n",
    "\tx = layers.Dense(np.product(initial_dimensions)*256, use_bias=False)(inputs)\n",
    "\tx = layers.LeakyReLU(0.2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\n",
    "\tx = layers.Reshape((*initial_dimensions, 256))(x)\n",
    "\n",
    "\tx = upsampling_transposed_conv_block(x, 256)\n",
    "\tx = upsampling_transposed_conv_block(x, 256)\n",
    "\n",
    "\tx = layers.UpSampling2D()(x)\n",
    "\tx = layers.Conv2DTranspose(3, kernel_size=(3, 3), padding='same')(x)\n",
    "\toutputs = tf.keras.activations.tanh(x)\n",
    "\n",
    "\tassert outputs.get_shape()[1:] == IMAGE_SHAPE, f'output tensor\\'s shapes are wrong! {outputs.get_shape()}'\n",
    "\n",
    "\tmodel = tf.keras.Model(inputs, outputs, name='generator')\n",
    "\t\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizer,\n",
    "\t\tloss=loss_function\n",
    "\t)\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe5323-3f20-4d7f-aaec-f20f75a5ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_generator_loss(fake_predictions):\n",
    "\treturn -tf.reduce_mean(fake_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e34b4b-8fe9-4e43-94d6-27ea5e6fc667",
   "metadata": {},
   "source": [
    "##### critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bc804-90c1-4254-afc7-025c061a6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_model(input_size, optimizer, loss_function):\n",
    "\tinputs = layers.Input(input_size)\n",
    "\n",
    "\tx = normalized_conv_block(inputs, 64, (5, 5))\n",
    "\tx = normalized_conv_block(x, 128)\n",
    "\n",
    "\tx = layers.Flatten()(x)\n",
    "\tx = layers.Dropout(0.2)(x)\n",
    "\toutputs = layers.Dense(1)(x)\n",
    "\n",
    "\tmodel = tf.keras.Model(inputs, outputs, name='critic')\n",
    "\t\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizer,\n",
    "\t\tloss=loss_function\n",
    "\t)\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cba4c-6ea9-4f33-be38-c08d25c64eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_critic_loss(real_predictions, fake_predictions):\n",
    "\treturn tf.reduce_mean(fake_predictions - real_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ead594-152e-4b16-a219-b559ef4ba37f",
   "metadata": {},
   "source": [
    "##### wgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28606ce1-a728-4a5d-bfc0-2c5e9b0e5be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WGAN(tf.keras.Model):\n",
    "\tdef __init__(self, generator, critic, latent_dim=LATENT_DIM, batchsize=BATCHSIZE, critic_extra_steps=1, lambd=10):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.generator = generator\n",
    "\t\tself.critic = critic\n",
    "\t\tself.latent_dim = tf.constant(latent_dim, dtype='int32')\n",
    "\t\tself.batchsize = tf.Variable(BATCHSIZE, dtype='int32')\n",
    "\t\tself.critic_extra_steps = tf.constant(critic_extra_steps, dtype='int32')\n",
    "\t\tself.lambd = tf.constant(lambd, dtype='float32')\n",
    "\t\t\n",
    "\tdef compute_gradient_penalty(self, generated_images, real_images):\n",
    "\t\tepsilon = tf.random.uniform((self.batchsize, 1, 1, 1), 0, 1)\n",
    "\t\tinterpolated_generated_images = epsilon * real_images + (1-epsilon) * generated_images\n",
    "\n",
    "\t\twith tf.GradientTape() as gp_tape:\n",
    "\t\t\tgp_tape.watch(interpolated_generated_images)\n",
    "\t\t\tprediction = self.critic(interpolated_generated_images, training=True)\n",
    "\n",
    "\t\tgrads = gp_tape.gradient(prediction, interpolated_generated_images)\n",
    "\t\t\n",
    "\t\tnorms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=(1, 2, 3)))\n",
    "\t\tgradient_penalty = self.lambd * tf.reduce_mean(tf.square(norms - 1))\n",
    "\n",
    "\t\treturn gradient_penalty\n",
    "\t\n",
    "\tdef update_critic(self, real_images):\n",
    "\t\tnoise = tf.random.normal(shape=(self.batchsize, self.latent_dim))\n",
    "\n",
    "\t\twith tf.GradientTape() as c_tape:\n",
    "\t\t\tgenerated_images = self.generator(noise, training=True)\n",
    "\t\t\tfake_predictions = self.critic(generated_images, training=True)\n",
    "\t\t\treal_predictions = self.critic(real_images, training=True)\n",
    "\n",
    "\t\t\tc_cost = self.critic.loss(real_predictions, fake_predictions)\n",
    "\t\t\tgradient_penalty = self.compute_gradient_penalty(generated_images, real_images)\n",
    "\t\t\tc_loss = c_cost + gradient_penalty\n",
    "\t\t\n",
    "\t\tc_gradients = c_tape.gradient(c_loss, self.critic.trainable_variables)\n",
    "\t\tself.critic.optimizer.apply_gradients(zip(c_gradients, self.critic.trainable_variables))\n",
    "\t\t\n",
    "\t\treturn c_loss\n",
    "\t\n",
    "\tdef update_generator(self):\n",
    "\t\tnoise = tf.random.normal((self.batchsize, self.latent_dim))\n",
    "\t\t\n",
    "\t\twith tf.GradientTape() as g_tape:\n",
    "\t\t\tgenerated_images = self.generator(noise, training=True)\n",
    "\t\t\tfake_predictions = self.critic(generated_images, training=True)\n",
    "\t\t\tg_loss = self.generator.loss(fake_predictions)\n",
    "\t\t\n",
    "\t\tg_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "\t\tself.generator.optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "\t\t\n",
    "\t\treturn g_loss\n",
    "\t\n",
    "\tdef train_step(self, images):\n",
    "\t\tself.batchsize = tf.shape(images)[0]\n",
    "\t\t\n",
    "\t\tfor _ in range(self.critic_extra_steps):\n",
    "\t\t\tc_loss = self.update_critic(images)\n",
    "\t\t\t\n",
    "\t\tg_loss = self.update_generator()\n",
    "\t\t\n",
    "\t\treturn {'c_loss': c_loss, 'g_loss': g_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa45470-59c6-4ad4-b363-b3ec4b21465b",
   "metadata": {},
   "source": [
    "#### callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1d540-1350-4942-a834-1d5e1d35c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizerOnBatch(tf.keras.callbacks.Callback):\n",
    "\tdef __init__(self, latent_dim=LATENT_DIM):\n",
    "\t\tself.latent_dim = latent_dim\n",
    "\t\t\n",
    "\tdef on_batch_end(self, batch, logs=None):\n",
    "\t\tgenerate_sample_images(self.model.generator, self.latent_dim, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc012e2-1fa0-4b46-9290-a77eafb63e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizerOnEpoch(tf.keras.callbacks.Callback):\n",
    "\tdef __init__(self, latent_dim=LATENT_DIM):\n",
    "\t\tself.latent_dim = latent_dim\n",
    "\t\t\n",
    "\tdef on_epoch_end(self, epoch, logs=None):\n",
    "\t\tgenerate_sample_images(self.model.generator, self.latent_dim, training=True)\n",
    "\t\t\t\n",
    "\t\tif epoch % 5 == 0:\n",
    "\t\t\tf.savefig(Paths.COLLECTION_DIR/f'image_at_epoch_{epoch}.png', format='png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fd106-0a1e-4736-9ede-b189510ef656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Checkpointer(tf.keras.callbacks.Callback):\n",
    "\tdef on_epoch_end(self, epoch):\n",
    "\t\tif epoch % 25 == 0:\n",
    "\t\t\tcheckpoint.save(Paths.CHECKPOINT_DIR/'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05a1e4-940c-41ab-9ca8-0a68a72bc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\tdef __init__(self, init_lr, final_lr, final_step):\n",
    "\t\tself.init_lr = tf.cast(init_lr, 'float32')\n",
    "\t\tself.final_lr = tf.cast(final_lr, 'float32')\n",
    "\t\tself.final_step = tf.cast(final_step, 'float32')\n",
    "\t\t\n",
    "\tdef __call__(self, step):\n",
    "\t\treturn tf.cond(\n",
    "\t\t\ttf.greater_equal(step, FINAL_STEP),\n",
    "\t\t\ttrue_fn=lambda: self.final_lr,\n",
    "\t\t\tfalse_fn=lambda: -(tf.sqrt(step * self.final_step) / self.final_step) * (self.init_lr - self.final_lr) + self.init_lr\n",
    "\t\t)\n",
    "\t\n",
    "\tdef get_config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'init_lr': tf.get_static_value(self.init_lr),\n",
    "\t\t\t'final_lr': tf.get_static_value(self.final_lr),\n",
    "\t\t\t'final_step': tf.get_static_value(self.final_step)\n",
    "\t\t\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f20e4-8e0a-4796-b029-f608954a7a40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b9be6-b157-4359-8288-85a61c2e0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_schedule = CustomLearningRateSchedule(init_lr=1e-4, final_lr=1e-5, final_step=FINAL_STEP)\n",
    "critic_schedule = CustomLearningRateSchedule(init_lr=1e-4, final_lr=1e-7, final_step=FINAL_STEP*5)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(generator_schedule, 0, 0.9)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_schedule, 0, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80632d3-0204-40c7-a0c2-a5c4ded0057f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = get_generator_model(LATENT_DIM, generator_optimizer, compute_generator_loss)\n",
    "critic = get_critic_model(IMAGE_SHAPE, critic_optimizer, compute_critic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392754f-f00f-4a07-bb65-f41be3f95b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualizer_on_batch = VisualizerOnBatch()\n",
    "visualizer_on_epoch = VisualizerOnEpoch()\n",
    "checkpointer = Checkpointer()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=Paths.LOG_DIR, histogram_freq=1, profile_batch='300, 310')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc911bc-a828-48ed-b181-c4cee12ef228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# each callback takes resources away from training. For fastest training disable all callbacks.\n",
    "callbacks = [\n",
    "\t# visualizer_on_batch,\n",
    "\t# visualizer_on_epoch,\n",
    "\t# checkpointer,\n",
    "\t# tensorboard_cb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd795b4f-c7d8-4383-b6c1-9824e09941ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(\n",
    "\tgenerator=generator,\n",
    "\tcritic=critic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcbb10d-810b-4b08-a612-67e062e835a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wgan = WGAN(generator, critic)\n",
    "wgan.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fbf4d-4915-4035-a8cb-e8ecef87b3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "# setup_folders(FOLDERS_TO_SETUP)\n",
    "history = wgan.fit(train_dataset, shuffle=True, epochs=EPOCHS, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee24b59-9e34-4455-9e72-f0faa9747d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and display a single image\n",
    "noise = tf.random.normal((1, LATENT_DIM))\n",
    "\n",
    "generated_image = wgan.generator(noise, training=False)\n",
    "generated_image = denormalize_images(generated_image)\n",
    "\n",
    "f, axis = plt.subplots(1, 1, figsize=(5, 5))\n",
    "axis.imshow(generated_image[0])\n",
    "axis.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51669aae-02ca-4e68-8cca-16a62ab89a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and display a collage of images\n",
    "generate_sample_images(wgan.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731df67-dd74-4b3d-adc9-d263e5c9cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and display a collage of images\n",
    "generate_sample_images(wgan.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2fa3b-f65c-446e-8efe-aef71d9905c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_weights():\n",
    "\twgan.generator.save_weights(Paths.SAVED_MODELS_DIR/'generator')\n",
    "\twgan.critic.save_weights(Paths.SAVED_MODELS_DIR/'critic')\n",
    "# save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc84fe-3fc4-466f-ad05-83cc3beb4352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_weights():\n",
    "\twgan.generator.load_weights(Paths.SAVED_MODELS_DIR/'generator')\n",
    "\twgan.critic.load_weights(Paths.SAVED_MODELS_DIR/'critic')\n",
    "# load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6509ee9-eae6-464f-872f-2b61b44edf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 2, figsize=(30, 9))\n",
    "axs[0].plot(wgan.history.history['c_loss'])\n",
    "axs[0].title.set_text('critic loss')\n",
    "axs[1].plot(wgan.history.history['g_loss'])\n",
    "axs[1].title.set_text('generator loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34b70b-b80b-451f-b081-9c1f95cd2e56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### refrences\n",
    "http://modelai.gettysburg.edu/2020/wgan/Resources/Lesson5/WGAN-GP.pdf  \n",
    "https://keras.io/examples/generative/wgan_gp/  \n",
    "https://github.com/caogang/wgan-gp/blob/master/gan_mnist.py  \n",
    "https://developers.google.com/machine-learning/gan/loss  \n",
    "https://www.youtube.com/watch?v=pG0QZ7OddX4  \n",
    "https://distill.pub/2016/deconv-checkerboard/  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
